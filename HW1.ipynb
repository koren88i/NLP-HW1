{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions For LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_output_file(list_of_models, model_file):\n",
    "    file = codecs.open(model_file, \"w+\", \"utf-8\")\n",
    "    for index, model in enumerate(list_of_models):\n",
    "        file.write(f'{index + 1}-grams:\\n')\n",
    "        calc_and_print_probs(model, file)\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "\n",
    "def calc_and_print_probs(model, file):\n",
    "    final_model = {}\n",
    "    for items in model.items():\n",
    "        prefix = items[0]\n",
    "        counter = items[1]\n",
    "\n",
    "        keys = list(counter.keys())\n",
    "        values = list(counter.values())\n",
    "        probs = [v / sum(values) for v in values]\n",
    "        for index, key in enumerate(keys):\n",
    "            final_model[prefix + key] = np.log2(probs[index])\n",
    "\n",
    "    for item in final_model.items():\n",
    "        file.write(f'{item[0]}\\t{item[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions For Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(list_models):\n",
    "    result = {}\n",
    "    for dictionary in list_models:\n",
    "        result.update(dictionary)\n",
    "    return result\n",
    "\n",
    "def n_grams_to_dict(n_grams):\n",
    "    n_grams = filter(lambda x: x != '', n_grams.split(\"\\n\"))\n",
    "    n_grams = [gram for gram in n_grams]\n",
    "    n_grams = map(lambda x: x.split(\"\\t\"), n_grams)\n",
    "    n_grams = [gram for gram in n_grams]\n",
    "    n_grams = map(lambda x: (x[0], float(x[1])), n_grams)\n",
    "    n_grams = [gram for gram in n_grams]\n",
    "    return n_grams\n",
    "\n",
    "def model_file_to_dict(model_file):\n",
    "    file = codecs.open(model_file, \"r\", \"utf-8\")\n",
    "    file_string = file.read()\n",
    "    file_split = re.split(\"\\d+-grams:\\n\", file_string)\n",
    "    uni_grams = n_grams_to_dict(file_split[1])\n",
    "    bi_grams = n_grams_to_dict(file_split[2])\n",
    "    three_grams = n_grams_to_dict(file_split[3])\n",
    "    return dict(uni_grams), dict(bi_grams), dict(three_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm(corpus_file, model_file):\n",
    "    corpus_file = corpus_file.replace(\"\\n\", \"<ENTER>\")\n",
    "\n",
    "    three_grams = defaultdict(Counter)\n",
    "    bi_grams = defaultdict(Counter)\n",
    "    uni_grams = defaultdict(Counter)\n",
    "    previous_unigram = None\n",
    "    for i in range(0, len(corpus_file) - n_gram + 1):\n",
    "        if i > 0:\n",
    "            previous_unigram = corpus_file[i - 1]\n",
    "\n",
    "        curr_three_gram = corpus_file[i:i + n_gram]\n",
    "        curr_bi_gram = corpus_file[i:i + n_gram - 1]\n",
    "        curr_uni_gram = corpus_file[i]\n",
    "\n",
    "        three_grams[curr_three_gram[0:2]][curr_three_gram[2]] += 1\n",
    "        bi_grams[curr_bi_gram[0:1]][curr_bi_gram[1]] += 1\n",
    "\n",
    "        if previous_unigram == \"<\":\n",
    "            if curr_uni_gram != \"e\" and curr_uni_gram != \"s\":\n",
    "                uni_grams[''][curr_uni_gram] += 1\n",
    "        else:\n",
    "            uni_grams[''][curr_uni_gram] += 1\n",
    "\n",
    "    create_model_output_file([uni_grams, bi_grams, three_grams], model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_perplexity(input_file, model_file, weights):\n",
    "    model = create_model(model_file_to_dict(model_file))\n",
    "\n",
    "    cumulative_interpolate = 0\n",
    "    for i in range(0, len(input_file) - n_gram + 1):\n",
    "        curr_three_gram = input_file[i:i + n_gram]\n",
    "        p_interpolate = interpolate(curr_three_gram, model, weights)\n",
    "        if not p_interpolate == 0:\n",
    "            cumulative_interpolate += p_interpolate\n",
    "\n",
    "    cross_entropy = (-1) / len(input_file) *  cumulative_interpolate\n",
    "    perplexity = np.power(2, cross_entropy)\n",
    "\n",
    "    print(f'{model_file} perplexity = {perplexity}')\n",
    "    return perplexity\n",
    "\n",
    "\n",
    "def interpolate(curr_three_gram, model, weights):\n",
    "    try:\n",
    "        p_xy3 = model[curr_three_gram]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "    p_xy2 = model[curr_three_gram[1:]]\n",
    "    p_xy1 = model[curr_three_gram[-1]]\n",
    "\n",
    "    return weights[0] * p_xy3 + weights[1] * p_xy2 + weights[2] * p_xy1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['en', 'es', 'fr', 'in', 'it', 'nl', 'pt', 'tl']\n",
    "n_gram = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dict = {}\n",
    "for lang in languages[0:]:\n",
    "    df = pd.read_csv(\"./data/\" + lang + \".csv\")\n",
    "    train, test = train_test_split(df, test_size=0.1, random_state=12)\n",
    "    train_test_dict[lang] = (train, test)\n",
    "    train_corpus = \"<s>\" + \"<e><s>\".join(train[\"tweet_text\"].values) + \"<e>\"\n",
    "\n",
    "    lm(train_corpus, lang+\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing en\n",
      "en.txt perplexity = 12.579148233431042\n",
      "es.txt perplexity = 14.547181515257451\n",
      "fr.txt perplexity = 14.637219063967972\n",
      "in.txt perplexity = 14.994689146168547\n",
      "it.txt perplexity = 14.677917899475593\n",
      "nl.txt perplexity = 14.516354653594203\n",
      "pt.txt perplexity = 13.852343368246306\n",
      "tl.txt perplexity = 14.09422941109137\n",
      "testing es\n",
      "en.txt perplexity = 13.412594114804705\n",
      "es.txt perplexity = 11.97551320732334\n",
      "fr.txt perplexity = 12.768733416797108\n",
      "in.txt perplexity = 13.922002158147787\n",
      "it.txt perplexity = 12.40107344912731\n",
      "nl.txt perplexity = 14.030403392148576\n",
      "pt.txt perplexity = 11.810494740090974\n",
      "tl.txt perplexity = 13.765339993049025\n",
      "testing fr\n",
      "en.txt perplexity = 11.902169739629631\n",
      "es.txt perplexity = 12.042588314359762\n",
      "fr.txt perplexity = 12.350566691284433\n",
      "in.txt perplexity = 12.722596400274153\n",
      "it.txt perplexity = 12.478263420519045\n",
      "nl.txt perplexity = 12.860741295168705\n",
      "pt.txt perplexity = 11.807977918407149\n",
      "tl.txt perplexity = 12.188070455804684\n",
      "testing in\n",
      "en.txt perplexity = 15.191109506588399\n",
      "es.txt perplexity = 13.878568523015884\n",
      "fr.txt perplexity = 15.34364290868031\n",
      "in.txt perplexity = 13.062449569541691\n",
      "it.txt perplexity = 13.796956217015925\n",
      "nl.txt perplexity = 15.29165906037268\n",
      "pt.txt perplexity = 13.368077463037302\n",
      "tl.txt perplexity = 13.714972878137006\n",
      "testing it\n",
      "en.txt perplexity = 14.643971603522411\n",
      "es.txt perplexity = 13.307540541285796\n",
      "fr.txt perplexity = 14.315355692847177\n",
      "in.txt perplexity = 14.44408759795392\n",
      "it.txt perplexity = 12.28805304951493\n",
      "nl.txt perplexity = 15.34473384243453\n",
      "pt.txt perplexity = 12.844423392217049\n",
      "tl.txt perplexity = 14.130902035382489\n",
      "testing nl\n",
      "en.txt perplexity = 13.330103053810683\n",
      "es.txt perplexity = 13.16670385787899\n",
      "fr.txt perplexity = 13.530848973782343\n",
      "in.txt perplexity = 14.340804131215366\n",
      "it.txt perplexity = 13.616495817604825\n",
      "nl.txt perplexity = 12.27310504787855\n",
      "pt.txt perplexity = 13.111423653217898\n",
      "tl.txt perplexity = 13.645972795673583\n",
      "testing pt\n",
      "en.txt perplexity = 13.186475716388385\n",
      "es.txt perplexity = 12.246643276802354\n",
      "fr.txt perplexity = 13.27011772123853\n",
      "in.txt perplexity = 13.695018374936211\n",
      "it.txt perplexity = 12.379418407725426\n",
      "nl.txt perplexity = 14.155552166900149\n",
      "pt.txt perplexity = 11.898183648829097\n",
      "tl.txt perplexity = 13.356914426835367\n",
      "testing tl\n",
      "en.txt perplexity = 14.829559254831835\n",
      "es.txt perplexity = 14.60828721873379\n",
      "fr.txt perplexity = 15.499608731910124\n",
      "in.txt perplexity = 13.515339158181055\n",
      "it.txt perplexity = 14.216597548920362\n",
      "nl.txt perplexity = 15.14069816648195\n",
      "pt.txt perplexity = 13.688038383174838\n",
      "tl.txt perplexity = 12.572145494527962\n"
     ]
    }
   ],
   "source": [
    "for test_lang in languages[0:]:\n",
    "    print(f'testing {test_lang}')\n",
    "    test = train_test_dict[test_lang][1]\n",
    "    test_corpus = \"<s>\" + \"<e><s>\".join(test[\"tweet_text\"].values) + \"<e>\"\n",
    "\n",
    "    for model_lang in languages[0:]:\n",
    "        model_perplexity = eval_perplexity(test_corpus, model_lang + \".txt\", (0.4, 0.3, 0.3))\n",
    "        results_dict[test_lang][model_lang] = model_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           en         es         fr         in         it         nl  \\\n",
      "en  12.579148  13.412594  11.902170  15.191110  14.643972  13.330103   \n",
      "es  14.547182  11.975513  12.042588  13.878569  13.307541  13.166704   \n",
      "fr  14.637219  12.768733  12.350567  15.343643  14.315356  13.530849   \n",
      "in  14.994689  13.922002  12.722596  13.062450  14.444088  14.340804   \n",
      "it  14.677918  12.401073  12.478263  13.796956  12.288053  13.616496   \n",
      "nl  14.516355  14.030403  12.860741  15.291659  15.344734  12.273105   \n",
      "pt  13.852343  11.810495  11.807978  13.368077  12.844423  13.111424   \n",
      "tl  14.094229  13.765340  12.188070  13.714973  14.130902  13.645973   \n",
      "\n",
      "           pt         tl  \n",
      "en  13.186476  14.829559  \n",
      "es  12.246643  14.608287  \n",
      "fr  13.270118  15.499609  \n",
      "in  13.695018  13.515339  \n",
      "it  12.379418  14.216598  \n",
      "nl  14.155552  15.140698  \n",
      "pt  11.898184  13.688038  \n",
      "tl  13.356914  12.572145  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results_dict)\n",
    "df.to_csv(\"results.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test No Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing en\n",
      "en.txt perplexity = 8.734948496186254\n",
      "es.txt perplexity = 11.567575700954963\n",
      "fr.txt perplexity = 11.373073781066015\n",
      "in.txt perplexity = 11.563783254661384\n",
      "it.txt perplexity = 11.627493233505858\n",
      "nl.txt perplexity = 11.152567614890474\n",
      "pt.txt perplexity = 11.01931709578962\n",
      "tl.txt perplexity = 10.538736049888037\n",
      "testing es\n",
      "en.txt perplexity = 10.601739676461282\n",
      "es.txt perplexity = 8.31001929380021\n",
      "fr.txt perplexity = 9.911115153572338\n",
      "in.txt perplexity = 11.005726082119736\n",
      "it.txt perplexity = 9.430560174196232\n",
      "nl.txt perplexity = 11.348057922117972\n",
      "pt.txt perplexity = 8.866903699021753\n",
      "tl.txt perplexity = 10.588308390501053\n",
      "testing fr\n",
      "en.txt perplexity = 9.266709772777487\n",
      "es.txt perplexity = 9.449055970541984\n",
      "fr.txt perplexity = 8.554343517524382\n",
      "in.txt perplexity = 10.128192929092725\n",
      "it.txt perplexity = 9.813096670630404\n",
      "nl.txt perplexity = 10.182978266232286\n",
      "pt.txt perplexity = 9.365039673127827\n",
      "tl.txt perplexity = 9.532679723140928\n",
      "testing in\n",
      "en.txt perplexity = 12.284248150705066\n",
      "es.txt perplexity = 11.233398577962856\n",
      "fr.txt perplexity = 12.395548325242359\n",
      "in.txt perplexity = 9.263651134918216\n",
      "it.txt perplexity = 11.149373600334592\n",
      "nl.txt perplexity = 12.369893289049822\n",
      "pt.txt perplexity = 10.94876830027911\n",
      "tl.txt perplexity = 10.6198111030431\n",
      "testing it\n",
      "en.txt perplexity = 11.575470946994779\n",
      "es.txt perplexity = 10.109780719348224\n",
      "fr.txt perplexity = 11.15818412552023\n",
      "in.txt perplexity = 11.261693032071925\n",
      "it.txt perplexity = 8.444241039918715\n",
      "nl.txt perplexity = 12.455352667375156\n",
      "pt.txt perplexity = 9.84570199965765\n",
      "tl.txt perplexity = 10.87204588421176\n",
      "testing nl\n",
      "en.txt perplexity = 10.504276775620962\n",
      "es.txt perplexity = 10.704324636194666\n",
      "fr.txt perplexity = 10.826088273978643\n",
      "in.txt perplexity = 11.379947743221248\n",
      "it.txt perplexity = 11.198089227814952\n",
      "nl.txt perplexity = 8.632502075044615\n",
      "pt.txt perplexity = 10.837932562627582\n",
      "tl.txt perplexity = 10.766957341922968\n",
      "testing pt\n",
      "en.txt perplexity = 10.513063681040265\n",
      "es.txt perplexity = 9.207739221634357\n",
      "fr.txt perplexity = 10.483608173450342\n",
      "in.txt perplexity = 10.897499370315835\n",
      "it.txt perplexity = 9.451630240944452\n",
      "nl.txt perplexity = 11.552711208019373\n",
      "pt.txt perplexity = 8.073184065561845\n",
      "tl.txt perplexity = 10.407956062710602\n",
      "testing tl\n",
      "en.txt perplexity = 11.50098712446171\n",
      "es.txt perplexity = 11.466084680162997\n",
      "fr.txt perplexity = 12.089393589838703\n",
      "in.txt perplexity = 10.11363977287093\n",
      "it.txt perplexity = 10.969712005025333\n",
      "nl.txt perplexity = 11.759245341510848\n",
      "pt.txt perplexity = 10.659178504266194\n",
      "tl.txt perplexity = 8.430425248911664\n"
     ]
    }
   ],
   "source": [
    "results_dict_no_unigram = defaultdict(dict)\n",
    "for test_lang in languages[0:]:\n",
    "    print(f'testing {test_lang}')\n",
    "    test = train_test_dict[test_lang][1]\n",
    "    test_corpus = \"<s>\" + \"<e><s>\".join(test[\"tweet_text\"].values) + \"<e>\"\n",
    "\n",
    "    for model_lang in languages[0:]:\n",
    "        model_perplexity = eval_perplexity(test_corpus, model_lang + \".txt\", (0.6, 0.4, 0.0))\n",
    "        results_dict_no_unigram[test_lang][model_lang] = model_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           en         es         fr         in         it         nl  \\\n",
      "en   8.734948  10.601740   9.266710  12.284248  11.575471  10.504277   \n",
      "es  11.567576   8.310019   9.449056  11.233399  10.109781  10.704325   \n",
      "fr  11.373074   9.911115   8.554344  12.395548  11.158184  10.826088   \n",
      "in  11.563783  11.005726  10.128193   9.263651  11.261693  11.379948   \n",
      "it  11.627493   9.430560   9.813097  11.149374   8.444241  11.198089   \n",
      "nl  11.152568  11.348058  10.182978  12.369893  12.455353   8.632502   \n",
      "pt  11.019317   8.866904   9.365040  10.948768   9.845702  10.837933   \n",
      "tl  10.538736  10.588308   9.532680  10.619811  10.872046  10.766957   \n",
      "\n",
      "           pt         tl  \n",
      "en  10.513064  11.500987  \n",
      "es   9.207739  11.466085  \n",
      "fr  10.483608  12.089394  \n",
      "in  10.897499  10.113640  \n",
      "it   9.451630  10.969712  \n",
      "nl  11.552711  11.759245  \n",
      "pt   8.073184  10.659179  \n",
      "tl  10.407956   8.430425  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results_dict_no_unigram)\n",
    "df.to_csv(\"results_no_unigram.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
