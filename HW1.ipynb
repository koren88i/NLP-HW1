{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions For LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_output_file(list_of_models, model_file):\n",
    "    file = codecs.open(model_file, \"w+\", \"utf-8\")\n",
    "    for index, model in enumerate(list_of_models):\n",
    "        file.write(f'{index + 1}-grams:\\n')\n",
    "        calc_and_print_probs(model, file)\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "\n",
    "def calc_and_print_probs(model, file):\n",
    "    final_model = {}\n",
    "    for items in model.items():\n",
    "        prefix = items[0]\n",
    "        counter = items[1]\n",
    "\n",
    "        keys = list(counter.keys())\n",
    "        values = list(counter.values())\n",
    "        probs = [v / sum(values) for v in values]\n",
    "        for index, key in enumerate(keys):\n",
    "            final_model[prefix + key] = np.log2(probs[index])\n",
    "\n",
    "    for item in final_model.items():\n",
    "        file.write(f'{item[0]}\\t{item[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions For Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(list_models):\n",
    "    result = {}\n",
    "    for dictionary in list_models:\n",
    "        result.update(dictionary)\n",
    "    return result\n",
    "\n",
    "def n_grams_to_dict(n_grams):\n",
    "    n_grams = filter(lambda x: x != '', n_grams.split(\"\\n\"))\n",
    "    n_grams = [gram for gram in n_grams]\n",
    "    n_grams = map(lambda x: x.split(\"\\t\"), n_grams)\n",
    "    n_grams = [gram for gram in n_grams]\n",
    "    n_grams = map(lambda x: (x[0], float(x[1])), n_grams)\n",
    "    n_grams = [gram for gram in n_grams]\n",
    "    return n_grams\n",
    "\n",
    "def model_file_to_dict(model_file):\n",
    "    file = codecs.open(model_file, \"r\", \"utf-8\")\n",
    "    file_string = file.read()\n",
    "    file_split = re.split(\"\\d+-grams:\\n\", file_string)\n",
    "    uni_grams = n_grams_to_dict(file_split[1])\n",
    "    bi_grams = n_grams_to_dict(file_split[2])\n",
    "    three_grams = n_grams_to_dict(file_split[3])\n",
    "    return dict(uni_grams), dict(bi_grams), dict(three_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm(corpus_file, model_file):\n",
    "    corpus_file = corpus_file.replace(\"\\n\", \"<ENTER>\")\n",
    "\n",
    "    three_grams = defaultdict(Counter)\n",
    "    bi_grams = defaultdict(Counter)\n",
    "    uni_grams = defaultdict(Counter)\n",
    "    previous_unigram = None\n",
    "    for i in range(0, len(corpus_file) - n_gram + 1):\n",
    "        if i > 0:\n",
    "            previous_unigram = corpus_file[i - 1]\n",
    "\n",
    "        curr_three_gram = corpus_file[i:i + n_gram]\n",
    "        curr_bi_gram = corpus_file[i:i + n_gram - 1]\n",
    "        curr_uni_gram = corpus_file[i]\n",
    "\n",
    "        three_grams[curr_three_gram[0:2]][curr_three_gram[2]] += 1\n",
    "        bi_grams[curr_bi_gram[0:1]][curr_bi_gram[1]] += 1\n",
    "\n",
    "        if previous_unigram == \"<\":\n",
    "            if curr_uni_gram != \"e\" and curr_uni_gram != \"s\":\n",
    "                uni_grams[''][curr_uni_gram] += 1\n",
    "        else:\n",
    "            uni_grams[''][curr_uni_gram] += 1\n",
    "\n",
    "    create_model_output_file([uni_grams, bi_grams, three_grams], model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_perplexity(input_file, model_file, weights):\n",
    "    model = create_model(model_file_to_dict(model_file))\n",
    "\n",
    "    cumulative_interpolate = 0\n",
    "    for i in range(0, len(input_file) - n_gram + 1):\n",
    "        curr_three_gram = input_file[i:i + n_gram]\n",
    "        p_interpolate = interpolate(curr_three_gram, model, weights)\n",
    "        if not p_interpolate == 0:\n",
    "            cumulative_interpolate += p_interpolate\n",
    "\n",
    "    cross_entropy = (-1) / len(input_file) *  cumulative_interpolate\n",
    "    perplexity = np.power(2, cross_entropy)\n",
    "\n",
    "    print(f'{model_file} perplexity = {perplexity}')\n",
    "    return perplexity\n",
    "\n",
    "\n",
    "def interpolate(curr_three_gram, model, weights):\n",
    "    try:\n",
    "        p_xy3 = model[curr_three_gram]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "\n",
    "    p_xy2 = model[curr_three_gram[1:]]\n",
    "    p_xy1 = model[curr_three_gram[-1]]\n",
    "\n",
    "    return weights[0] * p_xy3 + weights[1] * p_xy2 + weights[2] * p_xy1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['en', 'es', 'fr', 'in', 'it', 'nl', 'pt', 'tl']\n",
    "n_gram = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dict = {}\n",
    "for lang in languages[0:]:\n",
    "    df = pd.read_csv(\"./data/\" + lang + \".csv\")\n",
    "    train, test = train_test_split(df, test_size=0.1, random_state=12)\n",
    "    train_test_dict[lang] = (train, test)\n",
    "    train_corpus = \"<s>\" + \"<e><s>\".join(train[\"tweet_text\"].values) + \"<e>\"\n",
    "\n",
    "    lm(train_corpus, lang+\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for test_lang in languages[0:]:\n",
    "    print(f'testing {test_lang}')\n",
    "    test = train_test_dict[test_lang][1]\n",
    "    test_corpus = \"<s>\" + \"<e><s>\".join(test[\"tweet_text\"].values) + \"<e>\"\n",
    "\n",
    "    for model_lang in languages[0:]:\n",
    "        model_perplexity = eval_perplexity(test_corpus, model_lang + \".txt\", (0.4, 0.3, 0.3))\n",
    "        results_dict[test_lang][model_lang] = model_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results_dict)\n",
    "df.to_csv(\"results.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test No Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_dict_no_unigram = defaultdict(dict)\n",
    "for test_lang in languages[0:]:\n",
    "    print(f'testing {test_lang}')\n",
    "    test = train_test_dict[test_lang][1]\n",
    "    test_corpus = \"<s>\" + \"<e><s>\".join(test[\"tweet_text\"].values) + \"<e>\"\n",
    "\n",
    "    for model_lang in languages[0:]:\n",
    "        model_perplexity = eval_perplexity(test_corpus, model_lang + \".txt\", (0.6, 0.4, 0.0))\n",
    "        results_dict_no_unigram[test_lang][model_lang] = model_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results_dict_no_unigram)\n",
    "df.to_csv(\"results_no_unigram.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
