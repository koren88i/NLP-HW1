{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions For LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_output_file(list_of_models, model_file):\n",
    "    file = codecs.open(model_file, \"w+\", \"utf-8\")\n",
    "    for index, model in enumerate(list_of_models):\n",
    "        file.write(f'{index + 1}-grams:\\n')\n",
    "        if index==0:\n",
    "            calc_and_print_probs(model, file, smoothing = True)\n",
    "        calc_and_print_probs(model, file, smoothing = False)\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "\n",
    "def calc_and_print_probs(model, file, smoothing):\n",
    "    final_model = {}\n",
    "    for items in model.items():\n",
    "        prefix = items[0]\n",
    "        counter = items[1]\n",
    "\n",
    "        keys = list(counter.keys())\n",
    "        values = list(counter.values())\n",
    "        probs = [v / sum(values) for v in values]\n",
    "        if smoothing:\n",
    "            unknown_prob = 1 / (sum(values))\n",
    "            probs = [prob + unknown_prob for prob in probs]\n",
    "        for index, key in enumerate(keys):\n",
    "            final_model[prefix + key] = np.log2(probs[index])\n",
    "\n",
    "    if smoothing:\n",
    "        final_model[\"UNKNOWN\"] = unknown_prob\n",
    "    for item in final_model.items():\n",
    "        file.write(f'{item[0]}\\t{item[1]}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Functions For Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(list_models):\n",
    "    result = {}\n",
    "    for dictionary in list_models:\n",
    "        result.update(dictionary)\n",
    "    return result\n",
    "\n",
    "def n_grams_to_dict(n_grams):\n",
    "    n_grams = filter(lambda x: x != '', n_grams.split(\"\\n\"))\n",
    "    n_grams = [gram for gram in n_grams]\n",
    "    n_grams = map(lambda x: x.split(\"\\t\"), n_grams)\n",
    "    n_grams = [gram for gram in n_grams]\n",
    "    n_grams = map(lambda x: (x[0], float(x[1])), n_grams)\n",
    "    n_grams = [gram for gram in n_grams]\n",
    "    return n_grams\n",
    "\n",
    "def model_file_to_dict(model_file):\n",
    "    file = codecs.open(model_file, \"r\", \"utf-8\")\n",
    "    file_string = file.read()\n",
    "    file_split = re.split(\"\\d+-grams:\\n\", file_string)\n",
    "    uni_grams = n_grams_to_dict(file_split[1])\n",
    "    bi_grams = n_grams_to_dict(file_split[2])\n",
    "    three_grams = n_grams_to_dict(file_split[3])\n",
    "    return dict(uni_grams), dict(bi_grams), dict(three_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm(corpus_file, model_file):\n",
    "    corpus_file = corpus_file.replace(\"\\n\", \"<ENTER>\")\n",
    "\n",
    "    three_grams = defaultdict(Counter)\n",
    "    bi_grams = defaultdict(Counter)\n",
    "    uni_grams = defaultdict(Counter)\n",
    "    previous_unigram = None\n",
    "    for i in range(0, len(corpus_file) - n_gram + 1):\n",
    "        if i > 0:\n",
    "            previous_unigram = corpus_file[i - 1]\n",
    "\n",
    "        curr_three_gram = corpus_file[i:i + n_gram]\n",
    "        curr_bi_gram = corpus_file[i:i + n_gram - 1]\n",
    "        curr_uni_gram = corpus_file[i]\n",
    "\n",
    "        three_grams[curr_three_gram[0:2]][curr_three_gram[2]] += 1\n",
    "        bi_grams[curr_bi_gram[0:1]][curr_bi_gram[1]] += 1\n",
    "\n",
    "        if previous_unigram == \"<\":\n",
    "            if curr_uni_gram != \"e\" and curr_uni_gram != \"s\":\n",
    "                uni_grams[''][curr_uni_gram] += 1\n",
    "        else:\n",
    "            uni_grams[''][curr_uni_gram] += 1\n",
    "    \n",
    "    create_model_output_file([uni_grams, bi_grams, three_grams], model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_perplexity(input_file, model_file, weights):\n",
    "    model = create_model(model_file_to_dict(model_file))\n",
    "\n",
    "    cumulative_interpolate = 0\n",
    "    for i in range(0, len(input_file) - n_gram + 1):\n",
    "        curr_three_gram = input_file[i:i + n_gram]\n",
    "        p_interpolate = interpolate(curr_three_gram, model, weights)\n",
    "        if not p_interpolate == 0:\n",
    "            cumulative_interpolate += p_interpolate\n",
    "\n",
    "    cross_entropy = (-1) / len(input_file) *  cumulative_interpolate\n",
    "    perplexity = np.power(2, cross_entropy)\n",
    "\n",
    "    print(f'{model_file} perplexity = {perplexity}')\n",
    "    return perplexity\n",
    "\n",
    "\n",
    "def interpolate(curr_three_gram, model, weights):\n",
    "    try:\n",
    "        p_xy3 = model[curr_three_gram]\n",
    "    except KeyError:\n",
    "        p_xy3 = model[\"UNKNOWN\"]\n",
    "\n",
    "    try:\n",
    "        p_xy2 = model[curr_three_gram[1:]]\n",
    "    except KeyError:\n",
    "        p_xy2 = model[\"UNKNOWN\"]\n",
    "\n",
    "    try:\n",
    "        p_xy1 = model[curr_three_gram[-1]]\n",
    "    except KeyError:\n",
    "        p_xy1 = model[\"UNKNOWN\"]\n",
    "\n",
    "    return weights[0] * p_xy3 + weights[1] * p_xy2 + weights[2] * p_xy1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['en', 'es', 'fr', 'in', 'it', 'nl', 'pt', 'tl']\n",
    "n_gram = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dict = {}\n",
    "for lang in languages[0:]:\n",
    "    df = pd.read_csv(\"./data/\" + lang + \".csv\")\n",
    "    train, test = train_test_split(df, test_size=0.1, random_state=12)\n",
    "    train_test_dict[lang] = (train, test)\n",
    "    train_corpus = \"<s>\" + \"<e><s>\".join(train[\"tweet_text\"].values) + \"<e>\"\n",
    "\n",
    "    lm(train_corpus, lang+\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing en\n",
      "en.txt perplexity = 14.954497192618483\n",
      "es.txt perplexity = 19.804420884686973\n",
      "fr.txt perplexity = 19.02182104573655\n",
      "in.txt perplexity = 19.470163930975538\n",
      "it.txt perplexity = 19.68963104407588\n",
      "nl.txt perplexity = 18.423846618094498\n",
      "pt.txt perplexity = 19.5427409014225\n",
      "tl.txt perplexity = 18.147270752302468\n",
      "testing es\n",
      "en.txt perplexity = 17.557307827163154\n",
      "es.txt perplexity = 14.045118821751924\n",
      "fr.txt perplexity = 16.74321793655993\n",
      "in.txt perplexity = 18.06237047489614\n",
      "it.txt perplexity = 16.391051860823453\n",
      "nl.txt perplexity = 18.854738321532977\n",
      "pt.txt perplexity = 15.665498565904697\n",
      "tl.txt perplexity = 18.21279103572767\n",
      "testing fr\n",
      "en.txt perplexity = 16.691777170820075\n",
      "es.txt perplexity = 16.981291175845612\n",
      "fr.txt perplexity = 14.487609506106248\n",
      "in.txt perplexity = 18.510414427937956\n",
      "it.txt perplexity = 17.429267995911037\n",
      "nl.txt perplexity = 18.269516274129263\n",
      "pt.txt perplexity = 17.270368732436058\n",
      "tl.txt perplexity = 18.025105577162282\n",
      "testing in\n",
      "en.txt perplexity = 20.447546580820212\n",
      "es.txt perplexity = 20.313889543123413\n",
      "fr.txt perplexity = 21.217396208172723\n",
      "in.txt perplexity = 15.392363234472947\n",
      "it.txt perplexity = 20.27490021822945\n",
      "nl.txt perplexity = 20.441302605482836\n",
      "pt.txt perplexity = 20.216526723310277\n",
      "tl.txt perplexity = 17.994469157813263\n",
      "testing it\n",
      "en.txt perplexity = 18.741254147358266\n",
      "es.txt perplexity = 17.047745440460996\n",
      "fr.txt perplexity = 18.436675643073922\n",
      "in.txt perplexity = 19.037878414305613\n",
      "it.txt perplexity = 14.4131391758287\n",
      "nl.txt perplexity = 20.207722147071493\n",
      "pt.txt perplexity = 17.018654245098762\n",
      "tl.txt perplexity = 18.496596601953843\n",
      "testing nl\n",
      "en.txt perplexity = 18.384435325802983\n",
      "es.txt perplexity = 19.606257619692478\n",
      "fr.txt perplexity = 19.183053017872158\n",
      "in.txt perplexity = 19.719234360979844\n",
      "it.txt perplexity = 20.147427157479065\n",
      "nl.txt perplexity = 14.826938711432758\n",
      "pt.txt perplexity = 20.011668881571666\n",
      "tl.txt perplexity = 19.60878624926089\n",
      "testing pt\n",
      "en.txt perplexity = 17.608717922975153\n",
      "es.txt perplexity = 15.613762399278091\n",
      "fr.txt perplexity = 17.471083874916175\n",
      "in.txt perplexity = 18.120523530265913\n",
      "it.txt perplexity = 16.208599824983754\n",
      "nl.txt perplexity = 19.124872977157107\n",
      "pt.txt perplexity = 13.756323800828488\n",
      "tl.txt perplexity = 17.921314501766954\n",
      "testing tl\n",
      "en.txt perplexity = 19.65231659519614\n",
      "es.txt perplexity = 20.510822147421035\n",
      "fr.txt perplexity = 21.316078561795955\n",
      "in.txt perplexity = 17.65648759596023\n",
      "it.txt perplexity = 19.7725515162251\n",
      "nl.txt perplexity = 20.213700093293838\n",
      "pt.txt perplexity = 19.719762467659265\n",
      "tl.txt perplexity = 14.694538512578903\n"
     ]
    }
   ],
   "source": [
    "for test_lang in languages[0:]:\n",
    "    print(f'testing {test_lang}')\n",
    "    test = train_test_dict[test_lang][1]\n",
    "    test_corpus = \"<s>\" + \"<e><s>\".join(test[\"tweet_text\"].values) + \"<e>\"\n",
    "\n",
    "    for model_lang in languages[0:]:\n",
    "        model_perplexity = eval_perplexity(test_corpus, model_lang + \".txt\", (0.4, 0.3, 0.3))\n",
    "        results_dict[test_lang][model_lang] = model_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           en         es         fr         in         it         nl  \\\n",
      "en  14.954497  17.557308  16.691777  20.447547  18.741254  18.384435   \n",
      "es  19.804421  14.045119  16.981291  20.313890  17.047745  19.606258   \n",
      "fr  19.021821  16.743218  14.487610  21.217396  18.436676  19.183053   \n",
      "in  19.470164  18.062370  18.510414  15.392363  19.037878  19.719234   \n",
      "it  19.689631  16.391052  17.429268  20.274900  14.413139  20.147427   \n",
      "nl  18.423847  18.854738  18.269516  20.441303  20.207722  14.826939   \n",
      "pt  19.542741  15.665499  17.270369  20.216527  17.018654  20.011669   \n",
      "tl  18.147271  18.212791  18.025106  17.994469  18.496597  19.608786   \n",
      "\n",
      "           pt         tl  \n",
      "en  17.608718  19.652317  \n",
      "es  15.613762  20.510822  \n",
      "fr  17.471084  21.316079  \n",
      "in  18.120524  17.656488  \n",
      "it  16.208600  19.772552  \n",
      "nl  19.124873  20.213700  \n",
      "pt  13.756324  19.719762  \n",
      "tl  17.921315  14.694539  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results_dict)\n",
    "df.to_csv(\"results.csv\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
